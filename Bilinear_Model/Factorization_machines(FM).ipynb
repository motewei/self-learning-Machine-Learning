{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因子分解机  \n",
    "This section is another common model for estimating user behavior in recommendation systems:factorization machines(FM)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过点击率(click through rate, CTR)预测用户点击其他物品的概率\n",
    "- 点击与未点击是一个二分类问题，可以使用logistics regression解决\n",
    "- logistics regression中feature $x_i$与$x_j$之间没有运算，相互独立；但是问题中feature是可能存在关联的，引入双线性改进预测:\n",
    "$$\\hat{y}(x)=\\theta_0+\\mathbf{\\theta^T x}+\\frac{1}{2}\\mathbf{x^T Wx}$$\n",
    "- one-hot encording.实际中使用独热编码来表示事务的离散特征，犹豫独热编码的特征向量维度高，稀疏性大，x_ix_j=0无法对w_{ij}进行梯度更新。\n",
    "- 因子分解机器模型：$$\\mathbf{W = VV^T}, \\mathbf{V}\\in \\mathbb{R}^{d\\times k}$$  \n",
    "\n",
    "最后得到FM的预测公式：\n",
    "$$\\hat{y}(x)=\\theta_0+\\sum^{d}_{i=1}\\theta_ix_i+\\frac{1}{2}\\sum^{k}_{l=1}((\\sum^{d}_{i=1}v_{il}x_i)^2-\\sum^{d}_{i=1}v^2_{il}x^2_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this section is a sample dataset for fm_dataset.csv, which contains the characteristics of an item that a user has viewed and whether the user has clicked on the item.Each row of the dataset contains an item,with the first 24 columns being its characteristics and the last column being 0 or 1,indicating that the user did no or had clicked on the item,respectivedly.Our goal is to predict user behavior on the test set based on input characteristics,which is a dichotomous problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在NumPy中，`np.random.seed(0)`的作用是设置随机数生成器的种子，以确保每次运行程序时产生的随机数序列是相同的。这种设置对于机器学习和其他需要随机性的任务很有用，因为它可以使得实验的结果可重复。如果不设置种子，每次运行程序时都会得到不同的随机数序列，这可能会导致实验结果的不稳定性。通过设置种子，可以使得每次运行程序时得到相同的随机数序列，便于结果的比较和调试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T13:21:47.627819Z",
     "start_time": "2024-01-21T13:21:47.574723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of x_train: 800\n",
      "size of x_test: 800\n",
      "feature numbers: 24\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics # The Evaluation Index function library in sklearn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# load dataset\n",
    "data = np.loadtxt('fm_dataset.csv', delimiter=',')\n",
    "\n",
    "# divide dataset\n",
    "np.random.seed(0)\n",
    "ratio = 0.8\n",
    "split = int(ratio * len(data))\n",
    "x_train = data[:split, :-1]\n",
    "y_train = data[:split, -1]\n",
    "x_test = data[:split, :-1]\n",
    "y_test = data[split:, -1]\n",
    "\n",
    "# feature numbers\n",
    "feature_num = x_train.shape[1]\n",
    "print('size of x_train:', len(x_train))\n",
    "print('size of x_test:', len(x_test))\n",
    "print('feature numbers:', feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T13:38:53.233794Z",
     "start_time": "2024-01-21T13:38:53.218597Z"
    }
   },
   "outputs": [],
   "source": [
    "class FM:\n",
    "    def __init__(self, feature_num, vector_dim):\n",
    "        # vector_dim represents the k in the formula\n",
    "        # and is the dimension of vecotr v\n",
    "        self.theta0 = 0.0 # constant terms\n",
    "        self.theta = np.zeros(feature_num) # Linear parameter\n",
    "        self.v = np.random.normal(size=(feature_num, vector_dim)) # Bilinear parameter\n",
    "        self.eps = 1e-6 # precision parameter\n",
    "        \n",
    "    def _logistic(self, x):\n",
    "        # utility function for converting predictions into probabilities\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def pred(self, x):\n",
    "        # linear term\n",
    "        linear_term = self.theta0 + x @ self.theta\n",
    "        # Bilinear term\n",
    "        square_of_sum = np.square(x @ self.v)\n",
    "        sum_of_square = np.suqare(x) @ np.square(self.v)\n",
    "        # final predict\n",
    "        y_pred = self._logistic(linear_term\n",
    "                               + 0.5 * np.sum(square_of_sum - sum_of_square, axis=1))\n",
    "        # In order to prevent the following gradients from being too large,\n",
    "        # the predicted values are clipped and limited to a certain range\n",
    "        y_pred = np.clip(y_pred, self.eps, 1 - self.eps)\n",
    "        return y_pred\n",
    "    \n",
    "    def update(self, grad0, grad_theta, grad_v, lr):\n",
    "        self.theta0 -= lr * grad0\n",
    "        self.theta -= lr * grad_theta\n",
    "        self.v -= lr * grad_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector_dim = 16\n",
    "learning_rate = 0.01\n",
    "lbd = 0.05\n",
    "max_training_step = 200\n",
    "batch_size = 32\n",
    "\n",
    "np.random.seed(0)\n",
    "model = FM(feature_num, vector_dim)\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "train_auc = []\n",
    "test_auc = []\n",
    "\n",
    "with tqdm(renge(max_training_step)) as pbar:\n",
    "    for epoch in pbar:\n",
    "        st = 0\n",
    "        while st < len(x_train):\n",
    "            ed = min(st + batch_size, len(x_train))\n",
    "            X = x_train[st: ed]\n",
    "            Y = y_train[st: ed]\n",
    "            st += batch_size\n",
    "            # calculate model predict\n",
    "            y_pred = model.pred(X)\n",
    "            # calculate Cross entropy loss\n",
    "            cross_entropy = -Y * np.log(y_pred) \\ \n",
    "                - (1 - Y) * np.log(1 - y_pred)\n",
    "            loss = np.sum(cross_entropy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l]",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
